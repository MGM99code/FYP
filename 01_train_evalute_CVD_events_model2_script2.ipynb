{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from imblearn.pipeline import Pipeline as ImbPipeline\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "import xgboost as xgb\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from mlxtend.classifier import StackingCVClassifier\n",
    "import joblib\n",
    "from sklearn.model_selection import KFold, cross_val_predict, StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, roc_auc_score\n",
    "import pandas as pd\n",
    "\n",
    "random_seed = 1234\n",
    "KFOLD_SPLIT = 3\n",
    "\n",
    "# --- X_smote + 10 fet using rf-rfe ---\n",
    "# 1234， 2345 is split 3\n",
    "# 2345, 42 is split 5\n",
    "# 333 : split 10\n",
    "\n",
    "# --- X_ros + 10 fet using rf-rfe ---\n",
    "# 111， split 3\n",
    "# 222, split 5\n",
    "# 555, split 10\n",
    "\n",
    "# --- X_smote + 48 fet ---\n",
    "# 25, split 3\n",
    "# 35, split 5\n",
    "# 65, split 10\n",
    "\n",
    "# --- X_ros + 48 fet ---\n",
    "# 255, split 3\n",
    "# 355, split 5\n",
    "# 655, split 10\n",
    "\n",
    "# --- X_ros + 14 fet using be ---\n",
    "# 616: split 3\n",
    "# 626: split 5\n",
    "# 636: split 10\n",
    "\n",
    "# --- X_smote + 14 fet using be ---\n",
    "# 716: split 3\n",
    "# 726: split 5\n",
    "# 736: split 10\n",
    "\n",
    "# --- 10 fet using be sfs backward ---\n",
    "# 666: split 3\n",
    "\n",
    "# --- 10 fet using be sfs forward ---\n",
    "# 888: split 3\n",
    "\n",
    "DATA_DIR = '/Users/malithidesilva/fyp/model_2/result2'\n",
    "RESULT_DIR = f'/Users/malithidesilva/fyp/model_2/result2/model2_results_{random_seed}'\n",
    "\n",
    "os.makedirs(RESULT_DIR, exist_ok=True)\n",
    "\n",
    "# Define models\n",
    "rf_model = RandomForestClassifier(random_state=random_seed)\n",
    "xgb_model = xgb.XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state = random_seed)\n",
    "dt_model = DecisionTreeClassifier(random_state=random_seed)\n",
    "gbm_model = GradientBoostingClassifier(n_estimators=100, random_state=random_seed)\n",
    "svc_model = SVC(probability=True, random_state=random_seed)\n",
    "knn_model = KNeighborsClassifier(n_neighbors=5)\n",
    "\n",
    "\n",
    "\n",
    "single_pipelines = {\n",
    "    'RF': ImbPipeline([\n",
    "        ('scaling', MinMaxScaler()),\n",
    "        ('classifier', rf_model)\n",
    "    ]),\n",
    "    'XGBoost': ImbPipeline([\n",
    "        ('scaling', MinMaxScaler()),\n",
    "        ('classifier', xgb_model)\n",
    "    ]),\n",
    "    'DT': ImbPipeline([\n",
    "        ('scaling', MinMaxScaler()),\n",
    "        ('classifier', dt_model)\n",
    "    ]),\n",
    "    'GBM': ImbPipeline([\n",
    "        ('scaling', MinMaxScaler()),\n",
    "        ('classifier', gbm_model)\n",
    "    ]),\n",
    "    'SVC': ImbPipeline([\n",
    "        ('scaling', MinMaxScaler()),\n",
    "        ('classifier', svc_model)\n",
    "    ]),\n",
    "    'KNN': ImbPipeline([\n",
    "        ('scaling', MinMaxScaler()),\n",
    "        ('classifier', knn_model)\n",
    "    ]),\n",
    "    \n",
    "}\n",
    "\n",
    "ensemble_pipelines = {\n",
    "    'ALL_RF': ImbPipeline([\n",
    "        ('scaling', MinMaxScaler()),\n",
    "        ('classifier', StackingCVClassifier(\n",
    "            classifiers=[rf_model, xgb_model, dt_model, gbm_model, svc_model, knn_model],\n",
    "            meta_classifier=rf_model,\n",
    "            cv=KFOLD_SPLIT,\n",
    "        ))\n",
    "    ]),\n",
    "    'ALL_XGBoost': ImbPipeline([\n",
    "        ('scaling', MinMaxScaler()),\n",
    "        ('classifier', StackingCVClassifier(\n",
    "            classifiers=[rf_model, xgb_model, dt_model, gbm_model, svc_model, knn_model],\n",
    "            meta_classifier=xgb_model,\n",
    "            cv=KFOLD_SPLIT,\n",
    "        ))\n",
    "    ]),\n",
    "    'ALL_SVC': ImbPipeline([\n",
    "        ('scaling', MinMaxScaler()),\n",
    "        ('classifier', StackingCVClassifier(\n",
    "            classifiers=[rf_model, xgb_model, dt_model, gbm_model, svc_model, knn_model],\n",
    "            meta_classifier=svc_model,\n",
    "            cv=KFOLD_SPLIT,\n",
    "        ))\n",
    "    ]),\n",
    "    'ALL_GBM': ImbPipeline([\n",
    "        ('scaling', MinMaxScaler()),\n",
    "        ('classifier', StackingCVClassifier(\n",
    "            classifiers=[rf_model, xgb_model, dt_model, gbm_model, svc_model, knn_model],\n",
    "            meta_classifier=gbm_model,\n",
    "            cv=KFOLD_SPLIT,\n",
    "        ))\n",
    "    ])\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def plot_confusion_matrix(cm, title='Confusion Matrix', cmap=plt.cm.Blues, save_path=None):\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(cm, annot=True, fmt='g', cmap=cmap, cbar=False)\n",
    "    plt.title(title)\n",
    "    plt.xlabel('Predicted labels')\n",
    "    plt.ylabel('True labels')\n",
    "    plt.tight_layout()\n",
    "\n",
    "    if save_path:\n",
    "        plt.savefig(save_path)\n",
    "    else:\n",
    "        plt.show()\n",
    "    plt.close()\n",
    "\n",
    "# Update extended_class_report to include plotting confusion matrix\n",
    "def extended_class_report(cm, model_name, data_split, result_suffix):\n",
    "    tn, fp, fn, tp = cm.ravel()\n",
    "\n",
    "    # Calculate additional metrics\n",
    "    ppv = tp / (tp + fp) if (tp + fp) != 0 else 0\n",
    "    npv = tn / (tn + fn) if (tn + fn) != 0 else 0\n",
    "    sensitivity = tp / (tp + fn) if (tp + fn) != 0 else 0\n",
    "    specificity = tn / (tn + fp) if (tn + fp) != 0 else 0\n",
    "\n",
    "    # Plot and save confusion matrix\n",
    "    save_path = os.path.join(RESULT_DIR, f'{model_name}_{data_split}_confusion_matrix_{result_suffix}.png')\n",
    "    plot_confusion_matrix(cm, title=f'{model_name} {data_split.capitalize()} Confusion Matrix', save_path=save_path)\n",
    "\n",
    "    return ppv, npv, sensitivity, specificity\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def draw_auc(actual_y, prob_y, saved_dir):\n",
    "\n",
    "    y = actual_y #label_binarize(actual_y, classes=np.unique(actual_y))\n",
    "    n_classes = y.shape[1]\n",
    "\n",
    "    plt.figure(figsize=(15,15))\n",
    "    # Compute ROC AUC for each class\n",
    "    for i in range(n_classes):\n",
    "        # Ensure prob_y is a numpy array, handle if it's a dataframe\n",
    "        if hasattr(prob_y, \"to_numpy\"):\n",
    "            prob_y = prob_y.to_numpy()\n",
    "        fpr, tpr, threshold = roc_curve(y[:, i], prob_y[:, i])\n",
    "        roc_auc_results = auc(fpr, tpr)\n",
    "        plt.plot(fpr, tpr, lw=2, label=f'Class {i} (area = {roc_auc_results:.2f})')\n",
    "\n",
    "    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title(f'Multiclass ROC Curve by One-vs-Rest, thres:{threshold}')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    # plt.show()\n",
    "    plt.savefig(saved_dir)\n",
    "    plt.close()\n",
    "\n",
    "# Function to convert numpy array to DataFrame\n",
    "def ensure_dataframe(data):\n",
    "    if isinstance(data, np.ndarray):\n",
    "        return pd.DataFrame(data)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_models(pipelines, X_train_selected, y_train_selected, X_test_selected, y_test_selected, result_suffix):\n",
    "    overview = []\n",
    "    for model_name, pipeline in pipelines.items():\n",
    "        model_result_dir = os.path.join(RESULT_DIR, f\"{model_name}_{result_suffix}\")\n",
    "        if not os.path.exists(model_result_dir):\n",
    "            os.makedirs(model_result_dir)\n",
    "        print(f'------- {model_name} -------')\n",
    "\n",
    "        print('>>> Fitting training model')\n",
    "\n",
    "        pipeline.fit(X_train_selected, y_train_selected)\n",
    "        y_train_pred = cross_val_predict(pipeline, X_train_selected, y_train_selected, cv=KFOLD_SPLIT)\n",
    "        y_train_pred_proba = cross_val_predict(pipeline, X_train_selected, y_train_selected, cv=KFOLD_SPLIT, method='predict_proba')[:, 1]\n",
    "\n",
    "        train_accuracy = accuracy_score(y_train_selected, y_train_pred)\n",
    "        train_conf_matrix = confusion_matrix(y_train_selected, y_train_pred)\n",
    "        train_pv, train_npv, train_sensitivity, train_specificity = extended_class_report(train_conf_matrix, model_name, 'train', result_suffix)\n",
    "        train_roc_auc = roc_auc_score(y_train_selected, y_train_pred_proba)\n",
    "\n",
    "        print('>>> Validating test set')\n",
    "\n",
    "        y_test_pred = pipeline.predict(X_test_selected)\n",
    "        y_test_pred_proba = pipeline.predict_proba(X_test_selected)[:, 1]\n",
    "\n",
    "        test_accuracy = accuracy_score(y_test_selected, y_test_pred)\n",
    "        test_conf_matrix = confusion_matrix(y_test_selected, y_test_pred)\n",
    "        test_pv, test_npv, test_sensitivity, test_specificity = extended_class_report(test_conf_matrix, model_name, 'test', result_suffix)\n",
    "        test_roc_auc = roc_auc_score(y_test_selected, y_test_pred_proba)\n",
    "\n",
    "        print(f'Results: {train_roc_auc}, {test_roc_auc}')\n",
    "\n",
    "        pd.DataFrame(train_conf_matrix).to_csv(os.path.join(model_result_dir, f'{model_name}_train_cm.csv'))\n",
    "        pd.DataFrame(test_conf_matrix).to_csv(os.path.join(model_result_dir, f'{model_name}_test_cm.csv'))\n",
    "\n",
    "        overview.append([model_name, test_accuracy, test_roc_auc, test_pv, test_npv, test_sensitivity, test_specificity, train_accuracy, train_roc_auc, train_pv, train_npv, train_sensitivity, train_specificity, train_roc_auc-test_roc_auc])\n",
    "\n",
    "        pred_to_save = {\n",
    "            'y_train_pred': y_train_pred,\n",
    "            'y_train_pred_proba': y_train_pred_proba,\n",
    "            'y_test_pred': y_test_pred,\n",
    "            'y_test_pred_proba': y_test_pred_proba,\n",
    "        }\n",
    "\n",
    "        joblib.dump(pred_to_save, os.path.join(model_result_dir, f'{model_name}_pred_values.pkl'))\n",
    "        joblib.dump(pipeline, os.path.join(model_result_dir, f'{model_name}_full_model.pkl'))\n",
    "\n",
    "    pd.DataFrame(overview, columns=['model_name', \n",
    "                                    'test_accuracy', \n",
    "                                    'test_roc_auc', \n",
    "                                    'test_ppv', \n",
    "                                    'test_npv', \n",
    "                                    'test_sensitivity', \n",
    "                                    'test_specificity', \n",
    "                                    'train_accuracy', \n",
    "                                    'train_roc_auc', \n",
    "                                    'train_ppv', \n",
    "                                    'train_npv', \n",
    "                                    'train_sensitivity', \n",
    "                                    'train_specificity',\n",
    "                                    'auc_diff'\n",
    "                                    ]).to_csv(os.path.join(RESULT_DIR, f'results_overview_{result_suffix}.csv'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "\n",
    "def evaluate_ensemble_models(pipelines, X_train_selected, y_train_selected, X_test_selected, y_test_selected, result_suffix):\n",
    "    overview = []\n",
    "    for model_name, pipeline in pipelines.items():\n",
    "        model_result_dir = os.path.join(RESULT_DIR, f\"{model_name}_{result_suffix}\")\n",
    "        if not os.path.exists(model_result_dir):\n",
    "            os.makedirs(model_result_dir)\n",
    "        print(f'------- {model_name} -------')\n",
    "\n",
    "        print('>>> Fitting training model')\n",
    "\n",
    "        pipeline.fit(X_train_selected, y_train_selected)\n",
    "        \n",
    "        # Use cross_val_predict only for classification tasks where classes_ attribute exists\n",
    "        if hasattr(pipeline, 'classes_'):\n",
    "            y_train_pred = cross_val_predict(pipeline, X_train_selected, y_train_selected, cv=KFOLD_SPLIT)\n",
    "            y_train_pred_proba = cross_val_predict(pipeline, X_train_selected, y_train_selected, cv=KFOLD_SPLIT, method='predict_proba')[:, 1]\n",
    "        else:\n",
    "            # Directly predict on training data\n",
    "            y_train_pred = pipeline.predict(X_train_selected)\n",
    "            y_train_pred_proba = pipeline.predict_proba(X_train_selected)[:, 1]\n",
    "\n",
    "        train_accuracy = accuracy_score(y_train_selected, y_train_pred)\n",
    "        train_conf_matrix = confusion_matrix(y_train_selected, y_train_pred)\n",
    "        train_pv, train_npv, train_sensitivity, train_specificity = extended_class_report(train_conf_matrix, model_name, 'train', result_suffix)\n",
    "        train_roc_auc = roc_auc_score(y_train_selected, y_train_pred_proba)\n",
    "\n",
    "        print('>>> Validating test set')\n",
    "\n",
    "        y_test_pred = pipeline.predict(X_test_selected)\n",
    "        y_test_pred_proba = pipeline.predict_proba(X_test_selected)[:, 1]\n",
    "\n",
    "        test_accuracy = accuracy_score(y_test_selected, y_test_pred)\n",
    "        test_conf_matrix = confusion_matrix(y_test_selected, y_test_pred)\n",
    "        test_pv, test_npv, test_sensitivity, test_specificity = extended_class_report(test_conf_matrix, model_name, 'test', result_suffix)\n",
    "        test_roc_auc = roc_auc_score(y_test_selected, y_test_pred_proba)\n",
    "\n",
    "        print(f'Results: {train_roc_auc}, {test_roc_auc}')\n",
    "\n",
    "        pd.DataFrame(train_conf_matrix).to_csv(os.path.join(model_result_dir, f'{model_name}_train_cm.csv'))\n",
    "        pd.DataFrame(test_conf_matrix).to_csv(os.path.join(model_result_dir, f'{model_name}_test_cm.csv'))\n",
    "\n",
    "        overview.append([model_name, test_accuracy, test_roc_auc, test_pv, test_npv, test_sensitivity, test_specificity, train_accuracy, train_roc_auc, train_pv, train_npv, train_sensitivity, train_specificity, train_roc_auc-test_roc_auc])\n",
    "\n",
    "        pred_to_save = {\n",
    "            'y_train_pred': y_train_pred,\n",
    "            'y_train_pred_proba': y_train_pred_proba,\n",
    "            'y_test_pred': y_test_pred,\n",
    "            'y_test_pred_proba': y_test_pred_proba,\n",
    "        }\n",
    "\n",
    "        joblib.dump(pred_to_save, os.path.join(model_result_dir, f'{model_name}_pred_values.pkl'))\n",
    "        joblib.dump(pipeline, os.path.join(model_result_dir, f'{model_name}_full_model.pkl'))\n",
    "\n",
    "    pd.DataFrame(overview, columns=['model_name', \n",
    "                                    'test_accuracy', \n",
    "                                    'test_roc_auc', \n",
    "                                    'test_ppv', \n",
    "                                    'test_npv', \n",
    "                                    'test_sensitivity', \n",
    "                                    'test_specificity', \n",
    "                                    'train_accuracy', \n",
    "                                    'train_roc_auc', \n",
    "                                    'train_ppv', \n",
    "                                    'train_npv', \n",
    "                                    'train_sensitivity', \n",
    "                                    'train_specificity',\n",
    "                                    'auc_diff'\n",
    "                                    ]).to_csv(os.path.join(RESULT_DIR, f'results_overview_{result_suffix}.csv'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_shap_models(pipelines, X_train_selected, y_train_selected, X_test_selected, y_test_selected, result_suffix, is_shap=False):\n",
    "\n",
    "    overview = []\n",
    "    for model_name, pipeline in pipelines.items():\n",
    "        model_result_dir = os.path.join(RESULT_DIR, f\"{model_name}_{result_suffix}\")\n",
    "        if not os.path.exists(model_result_dir):\n",
    "            os.makedirs(model_result_dir)\n",
    "        print(f'------- {model_name} evaluation {result_suffix} -------')\n",
    "\n",
    "        print('>>> Fitting training model')\n",
    "\n",
    "        pipeline.fit(X_train_selected, y_train_selected)\n",
    "        y_train_pred = cross_val_predict(pipeline, X_train_selected, y_train_selected, cv=KFOLD_SPLIT)\n",
    "        y_train_pred_proba = cross_val_predict(pipeline, X_train_selected, y_train_selected, cv=KFOLD_SPLIT, method='predict_proba')[:, 1]\n",
    "\n",
    "        train_accuracy = accuracy_score(y_train_selected, y_train_pred)\n",
    "        train_conf_matrix = confusion_matrix(y_train_selected, y_train_pred)\n",
    "        train_pv, train_npv, train_sensitivity, train_specificity = extended_class_report(train_conf_matrix, model_name, 'train', result_suffix)\n",
    "        train_roc_auc = roc_auc_score(y_train_selected, y_train_pred_proba)\n",
    "\n",
    "        print('>>> Validating test set')\n",
    "\n",
    "        y_test_pred = pipeline.predict(X_test_selected)\n",
    "        y_test_pred_proba = pipeline.predict_proba(X_test_selected)[:, 1]\n",
    "\n",
    "        test_accuracy = accuracy_score(y_test_selected, y_test_pred)\n",
    "        test_conf_matrix = confusion_matrix(y_test_selected, y_test_pred)\n",
    "        test_pv, test_npv, test_sensitivity, test_specificity = extended_class_report(test_conf_matrix, model_name, 'test', result_suffix)\n",
    "        test_roc_auc = roc_auc_score(y_test_selected, y_test_pred_proba)\n",
    "\n",
    "        print(f'Results: Train ROC AUC = {train_roc_auc}, Test ROC AUC = {test_roc_auc}')\n",
    "\n",
    "        pd.DataFrame(train_conf_matrix).to_csv(os.path.join(model_result_dir, f'{model_name}_train_cm.csv'))\n",
    "        pd.DataFrame(test_conf_matrix).to_csv(os.path.join(model_result_dir, f'{model_name}_test_cm.csv'))\n",
    "\n",
    "        overview.append([model_name, test_accuracy, test_roc_auc, test_pv, test_npv, test_sensitivity, test_specificity, \n",
    "                         train_accuracy, train_roc_auc, train_pv, train_npv, train_sensitivity, train_specificity, \n",
    "                         train_roc_auc-test_roc_auc])\n",
    "\n",
    "        pred_to_save = {\n",
    "            'y_train_pred': y_train_pred,\n",
    "            'y_train_pred_proba': y_train_pred_proba,\n",
    "            'y_test_pred': y_test_pred,\n",
    "            'y_test_pred_proba': y_test_pred_proba,\n",
    "        }\n",
    "\n",
    "        joblib.dump(pred_to_save, os.path.join(model_result_dir, f'{model_name}_pred_values.pkl'))\n",
    "        joblib.dump(pipeline, os.path.join(model_result_dir, f'{model_name}_full_model.pkl'))\n",
    "\n",
    "    pd.DataFrame(overview, columns=['model_name', 'test_accuracy', 'test_roc_auc', 'test_ppv', 'test_npv', 'test_sensitivity', \n",
    "                                    'test_specificity', 'train_accuracy', 'train_roc_auc', 'train_ppv', 'train_npv', \n",
    "                                    'train_sensitivity', 'train_specificity', 'auc_diff']).to_csv(os.path.join(RESULT_DIR, f'results_overview_{result_suffix}.csv'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_shap_ensemble_models(pipelines, X_train_selected, y_train_selected, X_test_selected, y_test_selected, result_suffix, is_shap=False):\n",
    "    overview = []\n",
    "    for model_name, pipeline in pipelines.items():\n",
    "        model_result_dir = os.path.join(RESULT_DIR, f\"{model_name}_{result_suffix}\")\n",
    "        if not os.path.exists(model_result_dir):\n",
    "            os.makedirs(model_result_dir)\n",
    "        print(f'------- {model_name} evaluation {result_suffix} -------')\n",
    "\n",
    "        print('>>> Fitting training model')\n",
    "\n",
    "        pipeline.fit(X_train_selected, y_train_selected)\n",
    "        \n",
    "        # Use cross_val_predict only for classification tasks where classes_ attribute exists\n",
    "        if hasattr(pipeline, 'classes_'):\n",
    "            y_train_pred = cross_val_predict(pipeline, X_train_selected, y_train_selected, cv=KFOLD_SPLIT)\n",
    "            y_train_pred_proba = cross_val_predict(pipeline, X_train_selected, y_train_selected, cv=KFOLD_SPLIT, method='predict_proba')[:, 1]\n",
    "        else:\n",
    "            # Directly predict on training data\n",
    "            y_train_pred = pipeline.predict(X_train_selected)\n",
    "            y_train_pred_proba = pipeline.predict_proba(X_train_selected)[:, 1]\n",
    "\n",
    "        train_accuracy = accuracy_score(y_train_selected, y_train_pred)\n",
    "        train_conf_matrix = confusion_matrix(y_train_selected, y_train_pred)\n",
    "        train_pv, train_npv, train_sensitivity, train_specificity = extended_class_report(train_conf_matrix, model_name, 'train', result_suffix)\n",
    "        train_roc_auc = roc_auc_score(y_train_selected, y_train_pred_proba)\n",
    "\n",
    "        print('>>> Validating test set')\n",
    "\n",
    "        y_test_pred = pipeline.predict(X_test_selected)\n",
    "        y_test_pred_proba = pipeline.predict_proba(X_test_selected)[:, 1]\n",
    "\n",
    "        test_accuracy = accuracy_score(y_test_selected, y_test_pred)\n",
    "        test_conf_matrix = confusion_matrix(y_test_selected, y_test_pred)\n",
    "        test_pv, test_npv, test_sensitivity, test_specificity = extended_class_report(test_conf_matrix, model_name, 'test', result_suffix)\n",
    "        test_roc_auc = roc_auc_score(y_test_selected, y_test_pred_proba)\n",
    "\n",
    "        print(f'Results: Train ROC AUC = {train_roc_auc}, Test ROC AUC = {test_roc_auc}')\n",
    "\n",
    "        pd.DataFrame(train_conf_matrix).to_csv(os.path.join(model_result_dir, f'{model_name}_train_cm.csv'))\n",
    "        pd.DataFrame(test_conf_matrix).to_csv(os.path.join(model_result_dir, f'{model_name}_test_cm.csv'))\n",
    "\n",
    "        overview.append([model_name, test_accuracy, test_roc_auc, test_pv, test_npv, test_sensitivity, test_specificity, \n",
    "                         train_accuracy, train_roc_auc, train_pv, train_npv, train_sensitivity, train_specificity, \n",
    "                         train_roc_auc-test_roc_auc])\n",
    "\n",
    "        pred_to_save = {\n",
    "            'y_train_pred': y_train_pred,\n",
    "            'y_train_pred_proba': y_train_pred_proba,\n",
    "            'y_test_pred': y_test_pred,\n",
    "            'y_test_pred_proba': y_test_pred_proba,\n",
    "        }\n",
    "\n",
    "        joblib.dump(pred_to_save, os.path.join(model_result_dir, f'{model_name}_pred_values.pkl'))\n",
    "        joblib.dump(pipeline, os.path.join(model_result_dir, f'{model_name}_full_model.pkl'))\n",
    "\n",
    "    pd.DataFrame(overview, columns=['model_name', 'test_accuracy', 'test_roc_auc', 'test_ppv', 'test_npv', 'test_sensitivity', \n",
    "                                    'test_specificity', 'train_accuracy', 'train_roc_auc', 'train_ppv', 'train_npv', \n",
    "                                    'train_sensitivity', 'train_specificity', 'auc_diff']).to_csv(os.path.join(RESULT_DIR, f'results_overview_{result_suffix}.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading and evaluating resampled_data...\n",
      "------- RF -------\n",
      ">>> Fitting training model\n",
      ">>> Validating test set\n",
      "Results: 0.7159090909090908, 0.48750000000000004\n",
      "------- XGBoost -------\n",
      ">>> Fitting training model\n",
      ">>> Validating test set\n",
      "Results: 0.715909090909091, 0.6000000000000001\n",
      "------- DT -------\n",
      ">>> Fitting training model\n",
      ">>> Validating test set\n",
      "Results: 0.5568181818181819, 0.4875\n",
      "------- GBM -------\n",
      ">>> Fitting training model\n",
      ">>> Validating test set\n",
      "Results: 0.6528925619834711, 0.525\n",
      "------- SVC -------\n",
      ">>> Fitting training model\n",
      ">>> Validating test set\n",
      "Results: 0.722107438016529, 0.6875\n",
      "------- KNN -------\n",
      ">>> Fitting training model\n",
      ">>> Validating test set\n",
      "Results: 0.6580578512396695, 0.6000000000000001\n",
      "------- ALL_RF -------\n",
      ">>> Fitting training model\n",
      ">>> Validating test set\n",
      "Results: 0.9612603305785125, 0.7625\n",
      "------- ALL_XGBoost -------\n",
      ">>> Fitting training model\n",
      ">>> Validating test set\n",
      "Results: 0.8445247933884298, 0.525\n",
      "------- ALL_SVC -------\n",
      ">>> Fitting training model\n",
      ">>> Validating test set\n",
      "Results: 1.0, 0.6375\n",
      "------- ALL_GBM -------\n",
      ">>> Fitting training model\n",
      ">>> Validating test set\n",
      "Results: 0.9349173553719009, 0.6625\n",
      "Completed evaluation for resampled_data.\n",
      "Loading and evaluating rfe_data...\n",
      "------- RF -------\n",
      ">>> Fitting training model\n",
      ">>> Validating test set\n",
      "Results: 0.7657541322314049, 0.5187499999999999\n",
      "------- XGBoost -------\n",
      ">>> Fitting training model\n",
      ">>> Validating test set\n",
      "Results: 0.7138429752066116, 0.6\n",
      "------- DT -------\n",
      ">>> Fitting training model\n",
      ">>> Validating test set\n",
      "Results: 0.6477272727272727, 0.475\n",
      "------- GBM -------\n",
      ">>> Fitting training model\n",
      ">>> Validating test set\n",
      "Results: 0.7040289256198347, 0.5249999999999999\n",
      "------- SVC -------\n",
      ">>> Fitting training model\n",
      ">>> Validating test set\n",
      "Results: 0.7014462809917356, 0.55\n",
      "------- KNN -------\n",
      ">>> Fitting training model\n",
      ">>> Validating test set\n",
      "Results: 0.6815599173553719, 0.3375\n",
      "------- ALL_RF -------\n",
      ">>> Fitting training model\n",
      ">>> Validating test set\n",
      "Results: 0.9969008264462809, 0.4\n",
      "------- ALL_XGBoost -------\n",
      ">>> Fitting training model\n",
      ">>> Validating test set\n",
      "Results: 0.9958677685950413, 0.5750000000000001\n",
      "------- ALL_SVC -------\n",
      ">>> Fitting training model\n",
      ">>> Validating test set\n",
      "Results: 1.0, 0.43749999999999994\n",
      "------- ALL_GBM -------\n",
      ">>> Fitting training model\n",
      ">>> Validating test set\n",
      "Results: 0.8254132231404959, 0.5750000000000001\n",
      "Completed evaluation for rfe_data.\n",
      "Loading and evaluating be_data...\n",
      "File not found: /Users/malithidesilva/fyp/model2/new/selected_fet_data_be.pkl\n",
      "Loading and evaluating reduced_data...\n",
      "------- RF -------\n",
      ">>> Fitting training model\n",
      ">>> Validating test set\n",
      "Results: 0.743801652892562, 0.6000000000000001\n",
      "------- XGBoost -------\n",
      ">>> Fitting training model\n",
      ">>> Validating test set\n",
      "Results: 0.693698347107438, 0.6\n",
      "------- DT -------\n",
      ">>> Fitting training model\n",
      ">>> Validating test set\n",
      "Results: 0.5568181818181819, 0.4875\n",
      "------- GBM -------\n",
      ">>> Fitting training model\n",
      ">>> Validating test set\n",
      "Results: 0.6658057851239669, 0.525\n",
      "------- SVC -------\n",
      ">>> Fitting training model\n",
      ">>> Validating test set\n",
      "Results: 0.7215909090909092, 0.6875\n",
      "------- KNN -------\n",
      ">>> Fitting training model\n",
      ">>> Validating test set\n",
      "Results: 0.6763946280991735, 0.6625\n",
      "------- ALL_RF -------\n",
      ">>> Fitting training model\n",
      ">>> Validating test set\n",
      "Results: 0.896694214876033, 0.5187499999999999\n",
      "------- ALL_XGBoost -------\n",
      ">>> Fitting training model\n",
      ">>> Validating test set\n",
      "Results: 0.9731404958677686, 0.5562499999999999\n",
      "------- ALL_SVC -------\n",
      ">>> Fitting training model\n",
      ">>> Validating test set\n",
      "Results: 1.0, 0.54375\n",
      "------- ALL_GBM -------\n",
      ">>> Fitting training model\n",
      ">>> Validating test set\n",
      "Results: 0.9731404958677686, 0.74375\n",
      "Completed evaluation for reduced_data.\n",
      "Loading and evaluating shap_data...\n",
      "------- RF evaluation shap_data_N_10 -------\n",
      ">>> Fitting training model\n",
      ">>> Validating test set\n",
      "Results: Train ROC AUC = 0.7745351239669421, Test ROC AUC = 0.5874999999999999\n",
      "------- XGBoost evaluation shap_data_N_10 -------\n",
      ">>> Fitting training model\n",
      ">>> Validating test set\n",
      "Results: Train ROC AUC = 0.7246900826446282, Test ROC AUC = 0.575\n",
      "------- DT evaluation shap_data_N_10 -------\n",
      ">>> Fitting training model\n",
      ">>> Validating test set\n",
      "Results: Train ROC AUC = 0.5909090909090908, Test ROC AUC = 0.5499999999999999\n",
      "------- GBM evaluation shap_data_N_10 -------\n",
      ">>> Fitting training model\n",
      ">>> Validating test set\n",
      "Results: Train ROC AUC = 0.7050619834710745, Test ROC AUC = 0.575\n",
      "------- SVC evaluation shap_data_N_10 -------\n",
      ">>> Fitting training model\n",
      ">>> Validating test set\n",
      "Results: Train ROC AUC = 0.6451446280991736, Test ROC AUC = 0.575\n",
      "------- KNN evaluation shap_data_N_10 -------\n",
      ">>> Fitting training model\n",
      ">>> Validating test set\n",
      "Results: Train ROC AUC = 0.637654958677686, Test ROC AUC = 0.30625\n",
      "------- ALL_RF evaluation ensemble_shap_data_N_10 -------\n",
      ">>> Fitting training model\n",
      ">>> Validating test set\n",
      "Results: Train ROC AUC = 0.7706611570247934, Test ROC AUC = 0.50625\n",
      "------- ALL_XGBoost evaluation ensemble_shap_data_N_10 -------\n",
      ">>> Fitting training model\n",
      ">>> Validating test set\n",
      "Results: Train ROC AUC = 0.9963842975206612, Test ROC AUC = 0.73125\n",
      "------- ALL_SVC evaluation ensemble_shap_data_N_10 -------\n",
      ">>> Fitting training model\n",
      ">>> Validating test set\n",
      "Results: Train ROC AUC = 0.9710743801652894, Test ROC AUC = 0.58125\n",
      "------- ALL_GBM evaluation ensemble_shap_data_N_10 -------\n",
      ">>> Fitting training model\n",
      ">>> Validating test set\n",
      "Results: Train ROC AUC = 1.0, Test ROC AUC = 0.70625\n",
      "Completed evaluation for SHAP data with N=10.\n",
      "------- RF evaluation shap_data_N_12 -------\n",
      ">>> Fitting training model\n",
      ">>> Validating test set\n",
      "Results: Train ROC AUC = 0.7838326446280992, Test ROC AUC = 0.5875\n",
      "------- XGBoost evaluation shap_data_N_12 -------\n",
      ">>> Fitting training model\n",
      ">>> Validating test set\n",
      "Results: Train ROC AUC = 0.7148760330578513, Test ROC AUC = 0.65\n",
      "------- DT evaluation shap_data_N_12 -------\n",
      ">>> Fitting training model\n",
      ">>> Validating test set\n",
      "Results: Train ROC AUC = 0.5795454545454545, Test ROC AUC = 0.5499999999999999\n",
      "------- GBM evaluation shap_data_N_12 -------\n",
      ">>> Fitting training model\n",
      ">>> Validating test set\n",
      "Results: Train ROC AUC = 0.7091942148760331, Test ROC AUC = 0.6249999999999999\n",
      "------- SVC evaluation shap_data_N_12 -------\n",
      ">>> Fitting training model\n",
      ">>> Validating test set\n",
      "Results: Train ROC AUC = 0.646952479338843, Test ROC AUC = 0.5874999999999999\n",
      "------- KNN evaluation shap_data_N_12 -------\n",
      ">>> Fitting training model\n",
      ">>> Validating test set\n",
      "Results: Train ROC AUC = 0.5965909090909091, Test ROC AUC = 0.53125\n",
      "------- ALL_RF evaluation ensemble_shap_data_N_12 -------\n",
      ">>> Fitting training model\n",
      ">>> Validating test set\n",
      "Results: Train ROC AUC = 1.0, Test ROC AUC = 0.5375000000000001\n",
      "------- ALL_XGBoost evaluation ensemble_shap_data_N_12 -------\n",
      ">>> Fitting training model\n",
      ">>> Validating test set\n",
      "Results: Train ROC AUC = 0.7897727272727273, Test ROC AUC = 0.6499999999999999\n",
      "------- ALL_SVC evaluation ensemble_shap_data_N_12 -------\n",
      ">>> Fitting training model\n",
      ">>> Validating test set\n",
      "Results: Train ROC AUC = 0.7975206611570249, Test ROC AUC = 0.48750000000000004\n",
      "------- ALL_GBM evaluation ensemble_shap_data_N_12 -------\n",
      ">>> Fitting training model\n",
      ">>> Validating test set\n",
      "Results: Train ROC AUC = 1.0, Test ROC AUC = 0.6\n",
      "Completed evaluation for SHAP data with N=12.\n",
      "------- RF evaluation shap_data_N_14 -------\n",
      ">>> Fitting training model\n",
      ">>> Validating test set\n",
      "Results: Train ROC AUC = 0.7533574380165289, Test ROC AUC = 0.5687500000000001\n",
      "------- XGBoost evaluation shap_data_N_14 -------\n",
      ">>> Fitting training model\n",
      ">>> Validating test set\n",
      "Results: Train ROC AUC = 0.7267561983471076, Test ROC AUC = 0.7125\n",
      "------- DT evaluation shap_data_N_14 -------\n",
      ">>> Fitting training model\n",
      ">>> Validating test set\n",
      "Results: Train ROC AUC = 0.5795454545454545, Test ROC AUC = 0.5499999999999999\n",
      "------- GBM evaluation shap_data_N_14 -------\n",
      ">>> Fitting training model\n",
      ">>> Validating test set\n",
      "Results: Train ROC AUC = 0.7133264462809918, Test ROC AUC = 0.6375000000000001\n",
      "------- SVC evaluation shap_data_N_14 -------\n",
      ">>> Fitting training model\n",
      ">>> Validating test set\n",
      "Results: Train ROC AUC = 0.6286157024793388, Test ROC AUC = 0.6\n",
      "------- KNN evaluation shap_data_N_14 -------\n",
      ">>> Fitting training model\n",
      ">>> Validating test set\n",
      "Results: Train ROC AUC = 0.6128615702479339, Test ROC AUC = 0.475\n",
      "------- ALL_RF evaluation ensemble_shap_data_N_14 -------\n",
      ">>> Fitting training model\n",
      ">>> Validating test set\n",
      "Results: Train ROC AUC = 0.993801652892562, Test ROC AUC = 0.6125\n",
      "------- ALL_XGBoost evaluation ensemble_shap_data_N_14 -------\n",
      ">>> Fitting training model\n",
      ">>> Validating test set\n",
      "Results: Train ROC AUC = 1.0, Test ROC AUC = 0.6124999999999999\n",
      "------- ALL_SVC evaluation ensemble_shap_data_N_14 -------\n",
      ">>> Fitting training model\n",
      ">>> Validating test set\n",
      "Results: Train ROC AUC = 1.0, Test ROC AUC = 0.6375000000000001\n",
      "------- ALL_GBM evaluation ensemble_shap_data_N_14 -------\n",
      ">>> Fitting training model\n",
      ">>> Validating test set\n",
      "Results: Train ROC AUC = 0.921487603305785, Test ROC AUC = 0.6375\n",
      "Completed evaluation for SHAP data with N=14.\n",
      "------- RF evaluation shap_data_N_16 -------\n",
      ">>> Fitting training model\n",
      ">>> Validating test set\n",
      "Results: Train ROC AUC = 0.7786673553719008, Test ROC AUC = 0.625\n",
      "------- XGBoost evaluation shap_data_N_16 -------\n",
      ">>> Fitting training model\n",
      ">>> Validating test set\n",
      "Results: Train ROC AUC = 0.7122933884297521, Test ROC AUC = 0.7125\n",
      "------- DT evaluation shap_data_N_16 -------\n",
      ">>> Fitting training model\n",
      ">>> Validating test set\n",
      "Results: Train ROC AUC = 0.5568181818181819, Test ROC AUC = 0.5499999999999999\n",
      "------- GBM evaluation shap_data_N_16 -------\n",
      ">>> Fitting training model\n",
      ">>> Validating test set\n",
      "Results: Train ROC AUC = 0.7148760330578513, Test ROC AUC = 0.5874999999999999\n",
      "------- SVC evaluation shap_data_N_16 -------\n",
      ">>> Fitting training model\n",
      ">>> Validating test set\n",
      "Results: Train ROC AUC = 0.6895661157024793, Test ROC AUC = 0.7124999999999999\n",
      "------- KNN evaluation shap_data_N_16 -------\n",
      ">>> Fitting training model\n",
      ">>> Validating test set\n",
      "Results: Train ROC AUC = 0.6224173553719007, Test ROC AUC = 0.5375\n",
      "------- ALL_RF evaluation ensemble_shap_data_N_16 -------\n",
      ">>> Fitting training model\n",
      ">>> Validating test set\n",
      "Results: Train ROC AUC = 0.9607438016528925, Test ROC AUC = 0.8\n",
      "------- ALL_XGBoost evaluation ensemble_shap_data_N_16 -------\n",
      ">>> Fitting training model\n",
      ">>> Validating test set\n",
      "Results: Train ROC AUC = 0.7272727272727273, Test ROC AUC = 0.5875\n",
      "------- ALL_SVC evaluation ensemble_shap_data_N_16 -------\n",
      ">>> Fitting training model\n",
      ">>> Validating test set\n",
      "Results: Train ROC AUC = 0.96900826446281, Test ROC AUC = 0.75\n",
      "------- ALL_GBM evaluation ensemble_shap_data_N_16 -------\n",
      ">>> Fitting training model\n",
      ">>> Validating test set\n",
      "Results: Train ROC AUC = 0.8016528925619835, Test ROC AUC = 0.55\n",
      "Completed evaluation for SHAP data with N=16.\n",
      "------- RF evaluation shap_data_N_18 -------\n",
      ">>> Fitting training model\n",
      ">>> Validating test set\n",
      "Results: Train ROC AUC = 0.7861570247933883, Test ROC AUC = 0.575\n",
      "------- XGBoost evaluation shap_data_N_18 -------\n",
      ">>> Fitting training model\n",
      ">>> Validating test set\n",
      "Results: Train ROC AUC = 0.693698347107438, Test ROC AUC = 0.625\n",
      "------- DT evaluation shap_data_N_18 -------\n",
      ">>> Fitting training model\n",
      ">>> Validating test set\n",
      "Results: Train ROC AUC = 0.5681818181818182, Test ROC AUC = 0.5499999999999999\n",
      "------- GBM evaluation shap_data_N_18 -------\n",
      ">>> Fitting training model\n",
      ">>> Validating test set\n",
      "Results: Train ROC AUC = 0.7086776859504131, Test ROC AUC = 0.5499999999999999\n",
      "------- SVC evaluation shap_data_N_18 -------\n",
      ">>> Fitting training model\n",
      ">>> Validating test set\n",
      "Results: Train ROC AUC = 0.6825929752066116, Test ROC AUC = 0.7250000000000001\n",
      "------- KNN evaluation shap_data_N_18 -------\n",
      ">>> Fitting training model\n",
      ">>> Validating test set\n",
      "Results: Train ROC AUC = 0.6676136363636365, Test ROC AUC = 0.6375000000000001\n",
      "------- ALL_RF evaluation ensemble_shap_data_N_18 -------\n",
      ">>> Fitting training model\n",
      ">>> Validating test set\n",
      "Results: Train ROC AUC = 0.8186983471074379, Test ROC AUC = 0.63125\n",
      "------- ALL_XGBoost evaluation ensemble_shap_data_N_18 -------\n",
      ">>> Fitting training model\n",
      ">>> Validating test set\n",
      "Results: Train ROC AUC = 0.7954545454545454, Test ROC AUC = 0.68125\n",
      "------- ALL_SVC evaluation ensemble_shap_data_N_18 -------\n",
      ">>> Fitting training model\n",
      ">>> Validating test set\n",
      "Results: Train ROC AUC = 1.0, Test ROC AUC = 0.71875\n",
      "------- ALL_GBM evaluation ensemble_shap_data_N_18 -------\n",
      ">>> Fitting training model\n",
      ">>> Validating test set\n",
      "Results: Train ROC AUC = 0.7458677685950413, Test ROC AUC = 0.51875\n",
      "Completed evaluation for SHAP data with N=18.\n",
      "------- RF evaluation shap_data_N_20 -------\n",
      ">>> Fitting training model\n",
      ">>> Validating test set\n",
      "Results: Train ROC AUC = 0.7600723140495866, Test ROC AUC = 0.55\n",
      "------- XGBoost evaluation shap_data_N_20 -------\n",
      ">>> Fitting training model\n",
      ">>> Validating test set\n",
      "Results: Train ROC AUC = 0.7210743801652892, Test ROC AUC = 0.65\n",
      "------- DT evaluation shap_data_N_20 -------\n",
      ">>> Fitting training model\n",
      ">>> Validating test set\n",
      "Results: Train ROC AUC = 0.5795454545454545, Test ROC AUC = 0.4875\n",
      "------- GBM evaluation shap_data_N_20 -------\n",
      ">>> Fitting training model\n",
      ">>> Validating test set\n",
      "Results: Train ROC AUC = 0.678202479338843, Test ROC AUC = 0.475\n",
      "------- SVC evaluation shap_data_N_20 -------\n",
      ">>> Fitting training model\n",
      ">>> Validating test set\n",
      "Results: Train ROC AUC = 0.659607438016529, Test ROC AUC = 0.7375\n",
      "------- KNN evaluation shap_data_N_20 -------\n",
      ">>> Fitting training model\n",
      ">>> Validating test set\n",
      "Results: Train ROC AUC = 0.6381714876033058, Test ROC AUC = 0.74375\n",
      "------- ALL_RF evaluation ensemble_shap_data_N_20 -------\n",
      ">>> Fitting training model\n",
      ">>> Validating test set\n",
      "Results: Train ROC AUC = 0.9395661157024793, Test ROC AUC = 0.725\n",
      "------- ALL_XGBoost evaluation ensemble_shap_data_N_20 -------\n",
      ">>> Fitting training model\n",
      ">>> Validating test set\n",
      "Results: Train ROC AUC = 1.0, Test ROC AUC = 0.625\n",
      "------- ALL_SVC evaluation ensemble_shap_data_N_20 -------\n",
      ">>> Fitting training model\n",
      ">>> Validating test set\n",
      "Results: Train ROC AUC = 1.0, Test ROC AUC = 0.525\n",
      "------- ALL_GBM evaluation ensemble_shap_data_N_20 -------\n",
      ">>> Fitting training model\n",
      ">>> Validating test set\n",
      "Results: Train ROC AUC = 0.7892561983471074, Test ROC AUC = 0.4625\n",
      "Completed evaluation for SHAP data with N=20.\n",
      "------- RF evaluation shap_data_N_22 -------\n",
      ">>> Fitting training model\n",
      ">>> Validating test set\n",
      "Results: Train ROC AUC = 0.7551652892561984, Test ROC AUC = 0.5375\n",
      "------- XGBoost evaluation shap_data_N_22 -------\n",
      ">>> Fitting training model\n",
      ">>> Validating test set\n",
      "Results: Train ROC AUC = 0.7350206611570249, Test ROC AUC = 0.7\n",
      "------- DT evaluation shap_data_N_22 -------\n",
      ">>> Fitting training model\n",
      ">>> Validating test set\n",
      "Results: Train ROC AUC = 0.5909090909090908, Test ROC AUC = 0.5499999999999999\n",
      "------- GBM evaluation shap_data_N_22 -------\n",
      ">>> Fitting training model\n",
      ">>> Validating test set\n",
      "Results: Train ROC AUC = 0.71900826446281, Test ROC AUC = 0.5375\n",
      "------- SVC evaluation shap_data_N_22 -------\n",
      ">>> Fitting training model\n",
      ">>> Validating test set\n",
      "Results: Train ROC AUC = 0.6650309917355371, Test ROC AUC = 0.6625\n",
      "------- KNN evaluation shap_data_N_22 -------\n",
      ">>> Fitting training model\n",
      ">>> Validating test set\n",
      "Results: Train ROC AUC = 0.6567665289256198, Test ROC AUC = 0.65\n",
      "------- ALL_RF evaluation ensemble_shap_data_N_22 -------\n",
      ">>> Fitting training model\n",
      ">>> Validating test set\n",
      "Results: Train ROC AUC = 0.896694214876033, Test ROC AUC = 0.6749999999999999\n",
      "------- ALL_XGBoost evaluation ensemble_shap_data_N_22 -------\n",
      ">>> Fitting training model\n",
      ">>> Validating test set\n",
      "Results: Train ROC AUC = 0.9194214876033058, Test ROC AUC = 0.85\n",
      "------- ALL_SVC evaluation ensemble_shap_data_N_22 -------\n",
      ">>> Fitting training model\n",
      ">>> Validating test set\n",
      "Results: Train ROC AUC = 1.0, Test ROC AUC = 0.6375\n",
      "------- ALL_GBM evaluation ensemble_shap_data_N_22 -------\n",
      ">>> Fitting training model\n",
      ">>> Validating test set\n",
      "Results: Train ROC AUC = 0.8992768595041323, Test ROC AUC = 0.7375\n",
      "Completed evaluation for SHAP data with N=22.\n",
      "------- RF evaluation shap_data_N_24 -------\n",
      ">>> Fitting training model\n",
      ">>> Validating test set\n",
      "Results: Train ROC AUC = 0.7654958677685951, Test ROC AUC = 0.5874999999999999\n",
      "------- XGBoost evaluation shap_data_N_24 -------\n",
      ">>> Fitting training model\n",
      ">>> Validating test set\n",
      "Results: Train ROC AUC = 0.7179752066115701, Test ROC AUC = 0.675\n",
      "------- DT evaluation shap_data_N_24 -------\n",
      ">>> Fitting training model\n",
      ">>> Validating test set\n",
      "Results: Train ROC AUC = 0.5795454545454546, Test ROC AUC = 0.5499999999999999\n",
      "------- GBM evaluation shap_data_N_24 -------\n",
      ">>> Fitting training model\n",
      ">>> Validating test set\n",
      "Results: Train ROC AUC = 0.6962809917355373, Test ROC AUC = 0.55\n",
      "------- SVC evaluation shap_data_N_24 -------\n",
      ">>> Fitting training model\n",
      ">>> Validating test set\n",
      "Results: Train ROC AUC = 0.6608987603305785, Test ROC AUC = 0.7\n",
      "------- KNN evaluation shap_data_N_24 -------\n",
      ">>> Fitting training model\n",
      ">>> Validating test set\n",
      "Results: Train ROC AUC = 0.6255165289256199, Test ROC AUC = 0.61875\n",
      "------- ALL_RF evaluation ensemble_shap_data_N_24 -------\n",
      ">>> Fitting training model\n",
      ">>> Validating test set\n",
      "Results: Train ROC AUC = 0.9349173553719008, Test ROC AUC = 0.7562500000000001\n",
      "------- ALL_XGBoost evaluation ensemble_shap_data_N_24 -------\n",
      ">>> Fitting training model\n",
      ">>> Validating test set\n",
      "Results: Train ROC AUC = 0.9266528925619835, Test ROC AUC = 0.90625\n",
      "------- ALL_SVC evaluation ensemble_shap_data_N_24 -------\n",
      ">>> Fitting training model\n",
      ">>> Validating test set\n",
      "Results: Train ROC AUC = 0.9731404958677686, Test ROC AUC = 0.44375\n",
      "------- ALL_GBM evaluation ensemble_shap_data_N_24 -------\n",
      ">>> Fitting training model\n",
      ">>> Validating test set\n",
      "Results: Train ROC AUC = 0.9070247933884298, Test ROC AUC = 0.6312500000000001\n",
      "Completed evaluation for SHAP data with N=24.\n",
      "Evaluation completed for all datasets.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import pickle\n",
    "\n",
    "# Load N values from the file\n",
    "\n",
    "with open('N_values.pkl', 'rb') as f:\n",
    "    N_values = pickle.load(f)\n",
    "\n",
    "# Define dataset files with patterns\n",
    "dataset_files = {\n",
    "    'resampled_data': 'resampled_data_smote.pkl',\n",
    "    'rfe_data': 'selected_fet_data_RFE_rf.pkl',\n",
    "    'be_data': 'selected_fet_data_be.pkl',\n",
    "    'reduced_data': 'reduced_data.pkl',\n",
    "    'shap_data': 'shap_reduced_data_{N}.pkl'  # Pattern for SHAP data\n",
    "}\n",
    "\n",
    "# Main evaluation loop\n",
    "for dataset_name, data_file in dataset_files.items():\n",
    "    print(f\"Loading and evaluating {dataset_name}...\")\n",
    "\n",
    "    if dataset_name == 'shap_data':\n",
    "        for N in N_values:\n",
    "            file_path = os.path.join(DATA_DIR, data_file.format(N=N))\n",
    "            try:\n",
    "                data = joblib.load(file_path)\n",
    "                X_train_selected = data['X_train_shap']\n",
    "                y_train_selected = data['y_train_selected']\n",
    "                X_test_selected = data['X_test_shap']\n",
    "                y_test_selected = data['y_test_selected']\n",
    "\n",
    "                # Evaluate single pipelines\n",
    "                evaluate_shap_models(single_pipelines, X_train_selected, y_train_selected, X_test_selected, y_test_selected, result_suffix=f'shap_data_N_{N}', is_shap=True)\n",
    "                \n",
    "                # Evaluate ensemble pipelines\n",
    "                evaluate_shap_ensemble_models(ensemble_pipelines, X_train_selected, y_train_selected, X_test_selected, y_test_selected, result_suffix=f'ensemble_shap_data_N_{N}', is_shap=True)\n",
    "                \n",
    "                print(f\"Completed evaluation for SHAP data with N={N}.\")\n",
    "            except FileNotFoundError:\n",
    "                print(f\"File not found: {file_path}\")\n",
    "    else:\n",
    "        file_path = os.path.join(DATA_DIR, data_file)\n",
    "        try:\n",
    "            data = joblib.load(file_path)\n",
    "            if dataset_name == 'resampled_data':\n",
    "                X_train_selected = data['X_balanced']\n",
    "                y_train_selected = data['y_balanced']\n",
    "                X_test_selected = data['X_test_selected']\n",
    "                y_test_selected = data['y_test']\n",
    "            elif dataset_name == 'rfe_data':\n",
    "                X_train_selected = data['X_train_rfe']\n",
    "                y_train_selected = data['y_train_selected']\n",
    "                X_test_selected = data['X_test_rfe']\n",
    "                y_test_selected = data['y_test_selected']\n",
    "            elif dataset_name == 'be_data':\n",
    "                X_train_selected = data['X_train_be']\n",
    "                y_train_selected = data['y_train_selected']\n",
    "                X_test_selected = data['X_test_be']\n",
    "                y_test_selected = data['y_test_selected']\n",
    "            elif dataset_name == 'reduced_data':\n",
    "                X_train_selected = data['X_train_reduced']\n",
    "                y_train_selected = data['y_train_selected']\n",
    "                X_test_selected = data['X_test_reduced']\n",
    "                y_test_selected = data['y_test_selected']\n",
    "\n",
    "            # Evaluate single pipelines\n",
    "            evaluate_models(single_pipelines, X_train_selected, y_train_selected, X_test_selected, y_test_selected, result_suffix=dataset_name)\n",
    "            \n",
    "            # Evaluate ensemble pipelines\n",
    "            evaluate_ensemble_models(ensemble_pipelines, X_train_selected, y_train_selected, X_test_selected, y_test_selected, result_suffix=f'ensemble_{dataset_name}')\n",
    "            \n",
    "            print(f\"Completed evaluation for {dataset_name}.\")\n",
    "        except FileNotFoundError:\n",
    "            print(f\"File not found: {file_path}\")\n",
    "\n",
    "print(\"Evaluation completed for all datasets.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
